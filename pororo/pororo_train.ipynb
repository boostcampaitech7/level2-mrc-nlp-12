{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### import Pororo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/shark/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pororo\n",
    "from pororo import Pororo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 필요 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 모음\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from datasets import load_from_disk, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 초기 설정\n",
    "- nltk.download 진행 시 'punkt'가 아닌 'punkt_tab'을 입력  \n",
    "▶ 'punkt' 입력할 경우 mt(mt(text, src=\"ko\", tgt=\"en\"), tgt=\"en\", src=\"ko\")에서 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "nltk.download('punkt_tab')\n",
    "mt = Pororo(task=\"translation\", lang=\"multi\", model='transformer.large.multi.mtpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n"
     ]
    }
   ],
   "source": [
    "disk = \"/data/ephemeral/home/level2-mrc-nlp-12/data\"\n",
    "\n",
    "train_data = load_from_disk(disk + \"/train_dataset/\")\n",
    "train_dataset = train_data[\"train\"]\n",
    "print(len(train_data['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 역번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation(text):\n",
    "    return mt(mt(text, src=\"ko\", tgt=\"en\"), tgt=\"en\", src=\"ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(train_dataset, limit):\n",
    "    augmented_examples = []\n",
    "    for idx, example in enumerate(train_dataset):\n",
    "        if idx >= limit:\n",
    "            break\n",
    "        original_question = example['question']\n",
    "        \n",
    "        #역번역\n",
    "        back_translated_question = back_translation(original_question)\n",
    "        \n",
    "        # 새로운 예제 생성\n",
    "        new_example = example.copy()\n",
    "        new_example['question'] = back_translated_question\n",
    "        \n",
    "        augmented_examples.append(new_example)\n",
    "    \n",
    "    # 새로운 데이터셋 생성\n",
    "    aug_train_data = Dataset.from_dict(augmented_examples)\n",
    "    \n",
    "    return aug_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'add_items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#제한 개수\u001b[39;00m\n\u001b[1;32m      2\u001b[0m augmentation_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])       \u001b[38;5;66;03m#전체\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m aug_train_data \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation_limit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36maugment_data\u001b[0;34m(train_dataset, limit)\u001b[0m\n\u001b[1;32m     15\u001b[0m     augmented_questions\u001b[38;5;241m.\u001b[39mappend(new_example)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 새로운 데이터셋 생성\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m aug_train_data \u001b[38;5;241m=\u001b[39m DatasetDict({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_items\u001b[49m(augmented_questions)})\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aug_train_data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'add_items'"
     ]
    }
   ],
   "source": [
    "#제한 개수\n",
    "augmentation_limit = len(train_data['train'])       #전체\n",
    "\n",
    "aug_train_data = augment_data(train_dataset, augmentation_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##### 새로운 disk에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = DatasetDict({'train': train_dataset + aug_train_data['train']})\n",
    "combined_data.save_to_disk(disk + \"/pororo_train_data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
